{"models":[{"id":"7f180530-2e16-4116-9d26-f49fbed9d372","source":2,"name":"@hf/thebloke/deepseek-coder-6.7b-base-awq","description":"Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"terms","value":"https://huggingface.co/TheBloke/deepseek-coder-6.7B-base-AWQ"}]},{"id":"60474554-f03b-4ff4-8ecc-c1b7c71d7b29","source":2,"name":"@hf/thebloke/deepseek-coder-6.7b-instruct-awq","description":"Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"terms","value":"https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-AWQ"}]},{"id":"4c3a544e-da47-4336-9cea-c7cbfab33f16","source":1,"name":"@cf/deepseek-ai/deepseek-math-7b-instruct","description":"DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct"},{"property_id":"terms","value":"https://github.com/deepseek-ai/DeepSeek-Math/blob/main/LICENSE-MODEL"}]},{"id":"9d2ab560-065e-4d0d-a789-d4bc7468d33e","source":1,"name":"@cf/thebloke/discolm-german-7b-v1-awq","description":"DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/TheBloke/DiscoLM_German_7b_v1-AWQ"}]},{"id":"48dd2443-0c61-43b2-8894-22abddf1b081","source":1,"name":"@cf/tiiuae/falcon-7b-instruct","description":"Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/tiiuae/falcon-7b-instruct"}]},{"id":"0f002249-7d86-4698-aabf-8529ed86cefb","source":2,"name":"@hf/google/gemma-7b-it","description":"Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://ai.google.dev/gemma/docs"},{"property_id":"lora","value":"true"},{"property_id":"max_batch_prefill_tokens","value":"2048"},{"property_id":"max_input_length","value":"1512"},{"property_id":"max_total_tokens","value":"2048"},{"property_id":"terms","value":"https://ai.google.dev/gemma/terms"}]},{"id":"44774b85-08c8-4bb8-8d2a-b06ebc538a79","source":2,"name":"@hf/nousresearch/hermes-2-pro-mistral-7b","description":"Hermes 2 Pro on Mistral 7B is the new flagship 7B Hermes! Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"function_calling","value":"true"},{"property_id":"info","value":"https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B"}]},{"id":"85c5a3c6-24b0-45e7-b23a-023182578822","source":2,"name":"@hf/thebloke/llama-2-13b-chat-awq","description":"Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Llama 2 variant.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ"}]},{"id":"ca54bcd6-0d98-4739-9b3b-5c8b4402193d","source":1,"name":"@cf/meta/llama-2-7b-chat-fp16","description":"Full precision (fp16) generative text model with 7 billion parameters from Meta","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"false"},{"property_id":"info","value":"https://ai.meta.com/llama/"},{"property_id":"terms","value":"https://ai.meta.com/resources/models-and-libraries/llama-downloads/"}]},{"id":"9c95c39d-45b3-4163-9631-22f0c0dc3b14","source":1,"name":"@cf/meta/llama-2-7b-chat-int8","description":"Quantized (int8) generative text model with 7 billion parameters from Meta","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[]},{"id":"e11d8f45-7b08-499a-9eeb-71d4d3c8cbf9","source":1,"name":"@cf/meta/llama-3-8b-instruct","description":"Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"info","value":"https://llama.meta.com"},{"property_id":"terms","value":"https://llama.meta.com/llama3/license/#"}]},{"id":"31097538-a3ff-4e6e-bb56-ad0e1f428b61","source":1,"name":"@cf/meta/llama-3-8b-instruct-awq","description":"Quantized (int4) generative text model with 8 billion parameters from Meta.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"info","value":"https://llama.meta.com"},{"property_id":"terms","value":"https://llama.meta.com/llama3/license/#"}]},{"id":"41975cc2-c82e-4e98-b7b8-88ffb186a545","source":1,"name":"@cf/meta/llama-3.1-8b-instruct","description":"The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"}]},{"id":"3dcb4f2d-26a8-412b-b6e3-2a368beff66b","source":1,"name":"@cf/meta/llama-3.1-8b-instruct-awq","description":"Quantized (int4) generative text model with 8 billion parameters from Meta.\n","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"}]},{"id":"9b9c87c6-d4b7-494c-b177-87feab5904db","source":1,"name":"@cf/meta/llama-3.1-8b-instruct-fp8","description":"Llama 3.1 8B quantized to FP8 precision","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"}]},{"id":"2cbc033b-ded8-4e02-bbb2-47cf05d5cfe5","source":1,"name":"@cf/meta/llama-3.2-11b-vision-instruct","description":" The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"}]},{"id":"906a57fd-b018-4d6c-a43e-a296d4cc5839","source":1,"name":"@cf/meta/llama-3.2-1b-instruct","description":"The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"}]},{"id":"d9dc8363-66f4-4bb0-8641-464ee7bfc131","source":1,"name":"@cf/meta/llama-3.2-3b-instruct","description":"The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE"}]},{"id":"7a143886-c9bb-4a1c-be95-377b1973bc3b","source":1,"name":"@cf/meta/llama-3.3-70b-instruct-fp8-fast","description":"Llama 3.3 70B quantized to fp8 precision, optimized to be faster.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"terms","value":"https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE"}]},{"id":"d9b7a55c-cefa-4208-8ab3-11497a2b046c","source":2,"name":"@hf/thebloke/llamaguard-7b-awq","description":"Llama Guard is a model for classifying the safety of LLM prompts and responses, using a taxonomy of safety risks.\n","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"}]},{"id":"1a7b6ad6-9987-4bd3-a329-20ee8de93296","source":2,"name":"@hf/meta-llama/meta-llama-3-8b-instruct","description":"Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.\t","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[]},{"id":"c907d0f9-d69d-4e93-b501-4daeb4fd69eb","source":1,"name":"@cf/mistral/mistral-7b-instruct-v0.1","description":"Instruct fine-tuned version of the Mistral-7b generative text model with 7 billion parameters","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"false"},{"property_id":"info","value":"https://mistral.ai/news/announcing-mistral-7b/"},{"property_id":"lora","value":"true"}],"finetunes":[{"id":"39fb185c-762a-4633-a2ad-7a4462940608","name":"cf-public-magicoder","description":"LoRA adapter that enables Mistral to generate code","created_at":"2024-05-08 02:23:55.897","modified_at":"2024-05-08 02:23:55.897","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"911a83cf-d947-4c96-b4d2-a86c2c6d2b7f","name":"cf-public-cnn-summarization","description":"LoRA adapter that enables Mistral to summarize articles. https://huggingface.co/predibase/cnn","created_at":"2024-05-09 02:11:12.386","modified_at":"2024-05-09 02:11:12.386","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"c0b52d28-530b-4751-b7d9-afbdb4795990","name":"cf-public-jigsaw-classification","description":"LoRA adapter that enables Mistral to detect and classify toxic comments. https://huggingface.co/predibase/jigsaw","created_at":"2024-05-09 02:19:48.750","modified_at":"2024-05-09 02:19:48.750","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"}]},{"id":"980ec5e9-33c2-483a-a2d8-cd092fdf273f","source":2,"name":"@hf/thebloke/mistral-7b-instruct-v0.1-awq","description":"Mistral 7B Instruct v0.1 AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Mistral variant.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-AWQ"}]},{"id":"b97d7069-48d9-461c-80dd-445d20a632eb","source":2,"name":"@hf/mistral/mistral-7b-instruct-v0.2","description":"The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2. Mistral-7B-v0.2 has the following changes compared to Mistral-7B-v0.1: 32k context window (vs 8k context in v0.1), rope-theta = 1e6, and no Sliding-Window Attention.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"},{"property_id":"lora","value":"true"},{"property_id":"max_batch_prefill_tokens","value":"8192"},{"property_id":"max_input_length","value":"3072"},{"property_id":"max_total_tokens","value":"4096"}],"finetunes":[{"id":"39fb185c-762a-4633-a2ad-7a4462940608","name":"cf-public-magicoder","description":"LoRA adapter that enables Mistral to generate code","created_at":"2024-05-08 02:23:55.897","modified_at":"2024-05-08 02:23:55.897","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"911a83cf-d947-4c96-b4d2-a86c2c6d2b7f","name":"cf-public-cnn-summarization","description":"LoRA adapter that enables Mistral to summarize articles. https://huggingface.co/predibase/cnn","created_at":"2024-05-09 02:11:12.386","modified_at":"2024-05-09 02:11:12.386","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"},{"id":"c0b52d28-530b-4751-b7d9-afbdb4795990","name":"cf-public-jigsaw-classification","description":"LoRA adapter that enables Mistral to detect and classify toxic comments. https://huggingface.co/predibase/jigsaw","created_at":"2024-05-09 02:19:48.750","modified_at":"2024-05-09 02:19:48.750","public":1,"model":"@cf/mistral/mistral-7b-instruct-v0.2-lora"}]},{"id":"d2ba5c6b-bbb7-49d6-b466-900654870cd6","source":2,"name":"@hf/thebloke/neural-chat-7b-v3-1-awq","description":"This model is a fine-tuned 7B parameter LLM on the Intel Gaudi 2 processor from the mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"}]},{"id":"081054cd-a254-4349-855e-6dc0996277fa","source":1,"name":"@cf/openchat/openchat-3.5-0106","description":"OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/openchat/openchat-3.5-0106"}]},{"id":"673c56cc-8553-49a1-b179-dd549ec9209a","source":2,"name":"@hf/thebloke/openhermes-2.5-mistral-7b-awq","description":"OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"}]},{"id":"1d933df3-680f-4280-940d-da87435edb07","source":1,"name":"@cf/microsoft/phi-2","description":"Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/microsoft/phi-2"}]},{"id":"f8703a00-ed54-4f98-bdc3-cd9a813286f3","source":1,"name":"@cf/qwen/qwen1.5-0.5b-chat","description":"Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/qwen/qwen1.5-0.5b-chat"}]},{"id":"3222ddb3-e211-4fd9-9a6d-79a80e47b3a6","source":1,"name":"@cf/qwen/qwen1.5-1.8b-chat","description":"Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/qwen/qwen1.5-1.8b-chat"}]},{"id":"09d113a9-03c4-420e-b6f2-52ad4b3bed45","source":1,"name":"@cf/qwen/qwen1.5-14b-chat-awq","description":"Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/qwen/qwen1.5-14b-chat-awq"}]},{"id":"90a20ae7-7cf4-4eb3-8672-8fc4ee580635","source":1,"name":"@cf/qwen/qwen1.5-7b-chat-awq","description":"Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/qwen/qwen1.5-7b-chat-awq"}]},{"id":"1dc9e589-df6b-4e66-ac9f-ceff42d64983","source":1,"name":"@cf/defog/sqlcoder-7b-2","description":"This model is intended to be used by non-technical users to understand data inside their SQL databases. ","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/defog/sqlcoder-7b-2"},{"property_id":"terms","value":"https://creativecommons.org/licenses/by-sa/4.0/deed.en"}]},{"id":"e5ca943b-720f-4e66-aa8f-40e3d2770933","source":2,"name":"@hf/nexusflow/starling-lm-7b-beta","description":"We introduce Starling-LM-7B-beta, an open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF). Starling-LM-7B-beta is trained from Openchat-3.5-0106 with our new reward model Nexusflow/Starling-RM-34B and policy optimization method Fine-Tuning Language Models from Human Preferences (PPO).","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/Nexusflow/Starling-LM-7B-beta"},{"property_id":"max_batch_prefill_tokens","value":"8192"},{"property_id":"max_input_length","value":"3072"},{"property_id":"max_total_tokens","value":"4096"}]},{"id":"bf6ddd21-6477-4681-bbbe-24c3d5423e78","source":1,"name":"@cf/tinyllama/tinyllama-1.1b-chat-v1.0","description":"The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"}]},{"id":"b7fe7ad2-aeaf-47d2-8bfa-7a5ae22a2ab4","source":1,"name":"@cf/fblgit/una-cybertron-7b-v2-bf16","description":"Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"}]},{"id":"3976bab8-3810-4ad8-8580-ab1e22de7823","source":2,"name":"@hf/thebloke/zephyr-7b-beta-awq","description":"Zephyr 7B Beta AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Zephyr model variant.","task":{"id":"c329a1f9-323d-4e91-b2aa-582dd4188d34","name":"Text Generation","description":"Family of generative text models, such as large language models (LLM), that can be adapted for a variety of natural language tasks."},"tags":[],"properties":[{"property_id":"beta","value":"true"},{"property_id":"info","value":"https://huggingface.co/TheBloke/zephyr-7B-beta-AWQ"}]}]}
